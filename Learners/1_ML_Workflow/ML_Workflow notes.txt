RANDOM FOREST CLASSIFIER

What is Random Forest?
Random Forest is an ensemble machine learning algorithm that combines multiple decision trees to improve predictive performance.

It works by building many individual decision trees during training and outputs the mode (classification) or mean (regression) prediction of the individual trees.

How Does It Work?
Each tree is trained on a random subset of the training data (bootstrap sampling).

When splitting nodes during tree construction, only a random subset of features is considered to reduce correlation among trees.

This randomness reduces overfitting and improves generalization.

Key Characteristics:
Ensemble of Decision Trees: Aggregates multiple trees to make a final decision.

Bootstrap Aggregation (Bagging): Trees trained on random subsets of data.

Random Feature Selection: Adds randomness during node splits.

Non-parametric: Makes no assumptions about data distribution.

Handles high-dimensional data and categorical & numerical features.

Advantages:
High accuracy and robustness.

Handles missing values and maintains accuracy for missing data.

Works well on large datasets with many features.

Can estimate feature importance.

Less prone to overfitting than individual decision trees.

Disadvantages:
Model can be large and complex, requiring more memory.

Less interpretable compared to a single decision tree.

Training can be slower with very large forests.

Common Parameters:
n_estimators: Number of trees in the forest.

max_depth: Maximum depth of each tree.

min_samples_split: Minimum samples required to split a node.

max_features: Number of features to consider when looking for the best split.

Use Cases:
Classification tasks like image recognition, spam detection.

Regression problems.

Feature selection and importance analysis.

---

## ‚úÖ **Learning: Understood the Full ML Workflow ‚Äî From Data Acquisition to Model Deployment Using Flask**

---

### üìò **NOTES: End-to-End Machine Learning Workflow**

#### **1. Data Acquisition**

* Collect data from sources: CSV files, databases, APIs, or web scraping.
* Tools: `pandas`, `requests`, `BeautifulSoup`

#### **2. Data Cleaning**

* Handle missing values, remove duplicates, correct data types.
* Tools: `pandas`, `numpy`

#### **3. Exploratory Data Analysis (EDA)**

* Visualize data, understand distributions and relationships.
* Tools: `matplotlib`, `seaborn`

#### **4. Feature Engineering**

* Convert raw data into meaningful features (scaling, encoding, etc.).
* Tools: `scikit-learn`

#### **5. Model Building**

* Choose algorithm ‚Üí Train model ‚Üí Evaluate performance.
* Tools: `scikit-learn`, `xgboost`

#### **6. Model Evaluation**

* Use metrics like Accuracy, Precision, Recall, F1-score.
* Tools: `scikit-learn.metrics`

#### **7. Saving the Model**

* Serialize model using `pickle` or `joblib`.

#### **8. Deploying with Flask**

* Wrap model in an API with Flask ‚Üí Serve predictions.

---

## üßë‚Äçüíª **EXAMPLE CODE**: **Iris Flower Classifier (Deployed with Flask)**

---

### ‚úÖ Step 1: Train & Save the Model (`train_model.py`)

```python
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import pickle

# Load data
iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Save model
with open('iris_model.pkl', 'wb') as f:
    pickle.dump(model, f)

print("Model trained and saved as iris_model.pkl")
```

---

### ‚úÖ Step 2: Create Flask App (`app.py`)

```python
from flask import Flask, request, jsonify, render_template
import pickle
import numpy as np

# Load trained model
with open('iris_model.pkl', 'rb') as f:
    model = pickle.load(f)

app = Flask(__name__)

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    data = [float(x) for x in request.form.values()]
    final_input = np.array(data).reshape(1, -1)
    prediction = model.predict(final_input)
    return render_template('index.html', prediction_text=f'Predicted Iris class: {prediction[0]}')

if __name__ == '__main__':
    app.run(debug=True)
```